{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 Training\n",
    "\n",
    "In this notebook we will train the implementation of the VGG16 network provided in the vgg16.py file. We will be using the CIFAR-10 dataset for this task.\n",
    "\n",
    "**I am unable to train the model on my machine due to low memory of my GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10\n",
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
    "\n",
    "The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Get Data \"\"\"\n",
    "\n",
    "# File Path\n",
    "CIFAR_DIR = 'Data/cifar-10-batches-py/'\n",
    "\n",
    "# Load the Data\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        cifar_dict = pickle.load(fo, encoding='bytes')\n",
    "    return cifar_dict\n",
    "\n",
    "dirs = ['batches.meta','data_batch_1','data_batch_2','data_batch_3','data_batch_4','data_batch_5','test_batch']\n",
    "all_data = [0,1,2,3,4,5,6]\n",
    "\n",
    "for i,direc in zip(all_data,dirs):\n",
    "    all_data[i] = unpickle(CIFAR_DIR+direc)\n",
    "    \n",
    "batch_meta = all_data[0]\n",
    "data_batch1 = all_data[1]\n",
    "data_batch2 = all_data[2]\n",
    "data_batch3 = all_data[3]\n",
    "data_batch4 = all_data[4]\n",
    "data_batch5 = all_data[5]\n",
    "test_batch = all_data[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_batch1.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Loaded in this way, each of the batch files contains a dictionary with the following elements:\n",
    "\n",
    "data -- a 10000x3072 numpy array of uint8s. Each row of the array stores a 32x32 colour image. The first 1024 entries contain the red channel values, the next 1024 the green, and the final 1024 the blue. The image is stored in row-major order, so that the first 32 entries of the array are the red channel values of the first row of the image. labels -- a list of 10000 numbers in the range 0-9. The number at index i indicates the label of the ith image in the array data. The dataset contains another file, called batches.meta. It too contains a Python dictionary object. It has the following entries:\n",
    "\n",
    "label_names -- a 10-element list which gives meaningful names to the numeric labels in the labels array described above. For example, label_names[0] == \"airplane\", label_names[1] == \"automobile\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Data Images# Displ # Displ \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "X = data_batch1[b\"data\"] \n",
    "X = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"uint8\")\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "fig.add_subplot(1,3,1)\n",
    "plt.imshow(X[6])\n",
    "plt.axis('off')\n",
    "fig.add_subplot(1,3,2)\n",
    "plt.imshow(X[120])\n",
    "plt.axis('off')\n",
    "fig.add_subplot(1,3,3)\n",
    "plt.imshow(X[360])\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions for Dealing With Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(vec, vals=10):\n",
    "    '''\n",
    "    For use to one-hot encode the 10- possible labels\n",
    "    '''\n",
    "    n = len(vec)\n",
    "    out = np.zeros((n, vals))\n",
    "    out[range(n), vec] = 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifarHelper():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.i = 0\n",
    "        \n",
    "        # Grabs a list of all the data batches for training\n",
    "        self.all_train_batches = [data_batch1,data_batch2,data_batch3,data_batch4,data_batch5]\n",
    "        # Grabs a list of all the test batches (really just one batch)\n",
    "        self.test_batch = [test_batch]\n",
    "        \n",
    "        # Intialize some empty variables for later on\n",
    "        self.training_images = None\n",
    "        self.training_labels = None\n",
    "        \n",
    "        self.test_images = None\n",
    "        self.test_labels = None\n",
    "    \n",
    "    def set_up_images(self):\n",
    "        \n",
    "        print(\"Setting Up Training Images and Labels\")\n",
    "        \n",
    "        # Vertically stacks the training images\n",
    "        self.training_images = np.vstack([d[b\"data\"] for d in self.all_train_batches])\n",
    "        train_len = len(self.training_images)\n",
    "        \n",
    "        # Reshapes and normalizes training images\n",
    "        self.training_images = self.training_images.reshape(train_len,3,32,32).transpose(0,2,3,1)/255\n",
    "        # One hot Encodes the training labels (e.g. [0,0,0,1,0,0,0,0,0,0])\n",
    "        self.training_labels = one_hot_encode(np.hstack([d[b\"labels\"] for d in self.all_train_batches]), 10)\n",
    "        \n",
    "        print(\"Setting Up Test Images and Labels\")\n",
    "        \n",
    "        # Vertically stacks the test images\n",
    "        self.test_images = np.vstack([d[b\"data\"] for d in self.test_batch])\n",
    "        test_len = len(self.test_images)\n",
    "        \n",
    "        # Reshapes and normalizes test images\n",
    "        self.test_images = self.test_images.reshape(test_len,3,32,32).transpose(0,2,3,1)/255\n",
    "        # One hot Encodes the test labels (e.g. [0,0,0,1,0,0,0,0,0,0])\n",
    "        self.test_labels = one_hot_encode(np.hstack([d[b\"labels\"] for d in self.test_batch]), 10)\n",
    "\n",
    "        \n",
    "    def next_batch(self, batch_size):\n",
    "        if self.i + batch_size < 50000:\n",
    "            x = self.training_images[self.i:self.i+batch_size].reshape(batch_size,32,32,3)\n",
    "            y = self.training_labels[self.i:self.i+batch_size]\n",
    "        else:\n",
    "            x = self.training_images[self.i: ].reshape(-1,32,32,3)\n",
    "            y = self.training_labels[self.i: ]\n",
    "        self.i = (self.i + batch_size) % len(self.training_images)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the VGG16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#placeholder for input and dropout rate\n",
    "x = tf.placeholder(tf.float32, shape = [None, 32, 32, 3])\n",
    "y_true = tf.placeholder(tf.float32, shape = [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# Create the AlexNet model\n",
    "model = VGG16(x = x, keep_prob = keep_prob, num_classes = 10)\n",
    "\n",
    "#define activation of last layer as score\n",
    "score = model.fc8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels = y_true, logits = score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The optimiser used in this implementation is different\n",
    "# to that used in the paper.\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = 0.0001)\n",
    "train = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize all global variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 10\n",
    "batch_size = 128\n",
    "\n",
    "ch = CifarHelper()\n",
    "# pre-processes the data.\n",
    "ch.set_up_images()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    for j in range(epoch):\n",
    "        print(\"Epoch %d\" %(j + 1))\n",
    "        for i in range(0, 50000, batch_size):\n",
    "\n",
    "            # get next batch of data.\n",
    "            batch = ch.next_batch(batch_size)\n",
    "            # On training set.\n",
    "            sess.run(train, feed_dict = {x : batch[0], y_true : batch[1], keep_prob : 0.5})\n",
    "\n",
    "        # Get accuacy\n",
    "        matches = tf.equal(tf.argmax(score, 1), tf.argmax(y_true, 1))\n",
    "        acc = tf.reduce_mean(tf.cast(matches, tf.float32))\n",
    "\n",
    "        # On valid/test set.\n",
    "        test_accuracy = acc.eval(feed_dict = {x : ch.test_images, \n",
    "                                              y_true : ch.test_labels, keep_prob : 1.0})\n",
    "        \n",
    "        print(\"Accuracy: %g\" %(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
